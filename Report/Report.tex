\documentclass[12pt,letterpaper]{article}
\usepackage{cite}
\addbibresource{reportBibiography.bib}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{array}
\usepackage{dsfont}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bbold}
\usepackage{fullpage}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{mathrsfs}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{float}
\usepackage{gensymb}
\title{Black Box Systems: Reverse Engineering & Control\\MTHE 393 Interim Report}
\date{Monday March $14^{\textrm{th}}$, 2016}
\author{Gillian Sandison (10096880)\\Andrew Cantanna (10092489) \\Cameron Hudson (10092287)\\
James Szoke (10085958)\\}
\begin{document}
\begin{titlepage}
\maketitle
\end{titlepage}
\tableofcontents

\newpage

\section{Introduction}
\subsection{Scope}

The team was tasked with determining a linear, time-invariant state-space or transfer function that can be utilized to heuristically model an unknown system \cite{mathwebsite}.  A black box system which takes any input signal and produces a noisy output signal was provided. The internal workings of the black box were unknown, so the output noise was filtered and allowed the team to produce transfer functions and bode plots of the output signal. Given this information, the team was able to accurately approximate the system. This system will then be applied to data mining and amplifier profiling applications, taking into account economic, environmental and social impacts.
\par
\subsection{Purpose}
Filtering output signals is critical in many applications, as it allows for useful information to be extracted from the output signal.  If a noisy output signal is created, it will result in random information being produced. This will ultimately hinder the performance of the system. As a result, in order to effectively apply this system to an engineering application, the amount of noise produced in the output signal needs to be minimized in order to reduce the amount of random information being generated.


\section{Progress to date}

Describe in some detail what you have been doing and how.

\subsection{Methodology}

How have you been attacking the problem?  What sorts of assumptions have you had to make?  Why do you think those assumptions are valid?  Be specific about what you have done that has worked.  Do not spend even an iota of time saying what you tried and did not work.

\subsubsection{Filtering Options}
For any random input signal applied to the black box system, the output signal randomly generated noise. Three unique filtering options were applied in order to minimize the noise produced in the output.  The first filter utilized was a butter-worth filter.  A butter-worth filter is a low-pass filter which eliminates high frequency content in the output.  The second filter utilized was a median filter.  A median filter takes the average value of the output over small intervals. The output was uniquely produced 30 times, and the median filter was applied among these signals to generate a new averaged signal. The final filtering method utilized was unique, and involved redefining Matlab's random number generator. By implementing a new random number generator that only outputs zeros, the team was able to completely eliminate noise from the output.  Although this is a non traditional approach, it allowed for the team to produce more accurate bode plots and reverse engineer a precise filter.
\par

%\subsection{Results (if any)}

%If you have data to display, display it.  If you have a working model, tell us what it is.

\section{Applications}

\subsection{Data Mining}
One interesting application proposed for the use of this project is data mining. The spike in internet usage has created substantial amounts of readily available data. Data mining uses various patterns to manipulate and extract useful data from large sets, from clustering and classification, to summarization and estimation \cite{data mining 1}. These large data sets could be treated as an unknown system where general trends and outliers can be manipulated and used for specific applications. 
The key variables in a data mining control system are overshoot and steady state. The overshoot of a system indicates the immediate popularity of the advertisement.  If a system has a quick rise time and large overshoot, it suggests that the advertisement achieves a high level of “virality”. A slower rise time and smaller overshoot indicates that the advertisement may not be immediately successful, but the system may be able to achieve a non-zero stability more quickly. This implies that a steady stream of customers will adopt the product or service for a longer period of time, providing more consistent revenue. Steady state is an important measure for determining the length of an advertisements success. Having a non-zero steady state with a small steady state error is an ideal situation. This implies that the advertisement is being consistently viewed by a large audience. In real world applications, as time increases, the steady state will approach zero, meaning that the popularity of the advertisement will gradually decline. With these variables in mind, one could analyse advertisement campaigns and the produced response to design and implement a successful data mining control system.
Applications of data mining will target a large majority of internet users since many websites including Facebook, YouTube, and Netflix use recommender systems. These systems integrate data mining methods to make recommendations using knowledge acquired from the actions and qualities of user’s \cite{data mining 2}. Data mining allows for users to be exposed to products that they are currently interested in.  This results in easier accessibility to products that they may want to purchase, eliminating the need to actively search for the product online. 
There are a number of environmental, social, and economic obligations that these customers should be made aware of. 
In terms of the environment, the first question to be asked is: “Where is all this data stored?”. Server farms. The amount of log data managed by Facebook’s vice president, Jeff Rothschild, exceeds 25 terabytes daily, and as a result, each of Facebook’s data centers houses thousands of server’s \cite{data mining 3}. These server farms use vast amounts of energy, around the clock. In fact, in Silicon Valley, many data centers appear on the state government’s roster of the area’s top stationary diesel polluters \cite{data mining 4}. In addition to server farms, the devices on which the public accesses the internet is important. The lives of cell phones, smart watches, and laptops are easily dispensable, and in most cases are not disposed of properly posing further environmental concern. The devices on which internet is accessed raise economic trepidations as well as environmental.
Ethical concerns regarding data mining are conspicuous, as gross amounts of available data have to do with behaviour of the general public. In addition, the ways in which data is used raises questions concerning privacy, legality, and ethics. An example of disregard for ethics in data mining was seen in the early 2000s in the United States. Following the devastating events of 9/11, the Pentagon established the Total Information Awareness program, which made efforts to mine databases consisting of credit card records, car rentals, airline tickets, and so on \cite{data mining 5}. This program was shut down in 2003 by the U.S. Congress because of widespread privacy concerns \cite{data mining 6}.  Yet, regardless of intervention by Congress to limit potential abuses, the situation only became more complicated when in 2013 it was revealed that the U.S. and its major allies were conducting clandestine and far broader data mining programs.  Led by the NSA, programs such as PRISM and XKEYSCORE \cite{data mining 7} highlighted the extent to which data mining could be abused and underscored the need for strong policies and oversight to limit damage to personal privacy.  Clearly without such checks in place it took an insider to risk his life and safety to bring awareness to the issue \cite{data mining 8}.
Commercial data mining endeavours are not likely to achieve the scope seen by government programs but this does not mean they are immune to abuse and/or breach.  This was made evident in 2006 when it was found that AOL search histories occasionally included user identification numbers associated to particular queries.  By collecting enough search term-id pairs, researchers were able to identify individuals and their search habits on the site \cite{data mining 9}.   Damages to public trust and safety of any size should be considered unacceptable and care must be taken to limit invasions of privacy and unjust profiling based on data collected.  In fact, Fule and Roddick argue \cite{data mining 10} that there are two methods that can be used to mitigate the ‘effects of ethical compromise’.  The first method is to restrict access to data, hide or delete certain pieces of data or put privacy preserving mechanisms in place.  The second method is to allow unrestricted data mining but put in place a system of warnings, alerting users to potentially sensitive data.  Both methods have inherent drawbacks.  For instance, the first method has the potential to limit the effectiveness of any data collected while the second method is context dependent and may have to be tailored differently to different population segments \cite{data mining 11}.  
The potential earnings from utilizing data mining techniques are substantial. The market for big data analytics is projected to grow from 18.6 billion dollars in 2013 to 50 billion dollars in 2018 \cite{data mining 11}.  Due to this rapid growth, the potential benefits for companies is immense. The main goal for companies using the provided control system is to achieve a fast rise time and large overshoot. Targeting ads for specific users can lead to a more effective spread of content, ensuring that the ad will be shared with a greater number of users.  The more “viral” an advertisement is, the further reach the advertisement can attain, leading to more potential revenue. This can be seen in the case of the company wren. Wren released an advertisement called “first kiss” which went viral on YouTube and received over 78 million views. After the advertisement went viral, the companies sales increased by 14,000 percent \cite{data mining 12}.


\subsection{Reverse Engineering and its Implications}
Reverse engineering can be defined as the process of analyzing a system in order to determine how it works. This can be done by analyzing its inner components and trying to produce an enhanced understanding of the system \cite{reverseengineering}.
Duplication can be extremely valuable for understanding how a system operates.  In turn, this can allow for repairs, modifications and improvements to be implemented into the system\cite{reverseengineering}.
Reverse engineering is common practice in many industries, but tends to be prevalent in the automotive industry. An example of this is when an automotive manufacturing company needs a part, but the original manufacturer has gone out of business or does not produce the part any more. In order to use the component, they have to reproduce the existing part. Additionally, reverse engineering can be used to reduce the time spent on research and development for a new product.  This can be done by duplicating an existing part, and adding specific improvements to it\cite{reverseengineering2}.
\par
There have been a number of laws introduced around the concept of reverse engineering. In 1998, the United States implemented the Digital Millennium Copyright Act. The act forbids any service or device from being designed to circumvent, or even being marketed to circumvent any Digital Rights Management [4]. There is an exception to this act, stating that reverse engineering can be done if the modified and original components are interacting with each other.
If the product has been purchased legally, the product may be circumvented in order to identify and analyze the elements used within the product to develop a new product that is independent of the one being analyzed that interacts and operates with the current product. This is provided that the product being developed is not already available in the market, and that the users do not infringe on the title.
Additionally, implemented security measures on a product may be circumvented for the purpose of identifying and analyzing components of a product,to create a new product that provided that the user does not infringe on the title.
If a new product is successfully developed, it may be distributed if the new product is interoperable with the current product or is completely independent and does not infringe on the current title.
What regulatory concerns impinge upon the sort of technology you are developing?  Are there specific concerns that arise due to the sorts of customers you imagine your technology being useful for?
\subsection{Example Application 1: Guitar Amplifier Modeling and Control}
Guitar amplifiers  make up a core component of the sound of popular music over the last half century and continue to be a mainstay in recordings and live performances. This is despite the advent of technologies like synthesizers, DAWs (Digital Audio Workstations),  and VSTs (Virtual Studio Technology plugins) that have largely eliminated the need for many of the musicians and hardware tools featured on recordings in the past

\cite{specialIntroGuitar}.

A typical

\begin{figure}[ht!]
\centering
\includegraphics[width=100mm]{AmpBlockDiagram.JPG}
\caption{Block diagram of a typical guitar tube amplifier. \label{overflow}}
\end{figure}

The concept of digital amplifier simulation first rose to popularity
\par
From an economic perspective, the motivation clearly exists; the National Association of Music Merchants' member stores reported that musical instrument amplifier sales totaled \$186 million USD for 8 million units sold in the United States. \cite{NAMMReport}.

\section{Plans for the future}

Outline your plans for the remainder of the term.  Use a Gantt chart, whatever that is.

\bibliography{reportBibliography.bib}{}
\bibliographystyle{plain}

\end{document}
